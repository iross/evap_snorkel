{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/iaross/miniconda3/envs/evaporites/lib/python36.zip', '/home/iaross/miniconda3/envs/evaporites/lib/python3.6', '/home/iaross/miniconda3/envs/evaporites/lib/python3.6/lib-dynload', '', '/home/iaross/miniconda3/envs/evaporites/lib/python3.6/site-packages', '/home/iaross/miniconda3/envs/evaporites/lib/python3.6/site-packages/IPython/extensions', '/home/iaross/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, psycopg2\n",
    "from psycopg2.extensions import AsIs\n",
    "\n",
    "# Connect to Postgres\n",
    "with open('./credentials', 'r') as credential_yaml:\n",
    "    credentials = yaml.load(credential_yaml,Loader = yaml.SafeLoader)\n",
    "\n",
    "with open('./config', 'r') as config_yaml:\n",
    "    config = yaml.load(config_yaml, Loader = yaml.SafeLoader)\n",
    "    \n",
    "snorkel_connection = psycopg2.connect(\n",
    "    dbname=credentials['snorkel_postgres']['database'],\n",
    "    user=credentials['snorkel_postgres']['user'],\n",
    "    password=credentials['snorkel_postgres']['password'],\n",
    "    host=credentials['snorkel_postgres']['host'],\n",
    "    port=credentials['snorkel_postgres']['port'])\n",
    "snorkel_cursor=snorkel_connection.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CLEANING THE SLATE FOR SNORKEL \n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS candidate CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS context CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS document CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS feature CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS feature_key CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS gold_label CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS gold_label_key CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS label CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS label_key CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS marginal CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS prediction CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS prediction_key CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS sentence CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS span CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS spouse CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS stable_label CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS mineral CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS strat CASCADE;\n",
    "\"\"\")\n",
    "snorkel_cursor.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS strat_age CASCADE;\n",
    "\"\"\")\n",
    "snorkel_connection.commit()\n",
    "snorkel_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STARTING SNORKEL PROGRAM\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "## POSTGRES DATABASE CONN FOR SNORKEL \n",
    "os.environ['SNORKELDB']=\"postgres://evaporite:dummy@localhost:5432/evaporite_snorkel\"\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "from tqdm import tqdm \n",
    "start_time = datetime.now()\n",
    "# SPECIFYING CONNECTION TO EXISTING SENTENCES \n",
    "connection = psycopg2.connect(\n",
    "    dbname=credentials['postgres']['database'],\n",
    "    user=credentials['postgres']['user'],\n",
    "    password=credentials['postgres']['password'],\n",
    "    host=credentials['postgres']['host'],\n",
    "    port=credentials['postgres']['port'])\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# SPECIFYING CONNECTION TO SNORKEL \n",
    "snorkel_connection = psycopg2.connect(\n",
    "    dbname=credentials['snorkel_postgres']['database'],\n",
    "    user=credentials['snorkel_postgres']['user'],\n",
    "    password=credentials['snorkel_postgres']['password'],\n",
    "    host=credentials['snorkel_postgres']['host'],\n",
    "    port=credentials['snorkel_postgres']['port'])\n",
    "snorkel_cursor = snorkel_connection.cursor()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT(docid) FROM final_merged_sentences;\n",
    "\"\"\")\n",
    "\n",
    "count = 1\n",
    "for docid in cursor:\n",
    "    snorkel_cursor.execute(\"INSERT INTO context (id, type, stable_id) VALUES (nextval('context_id_seq'), 'document', %(stable_id)s)\", {\"stable_id\": docid[0] + \"::document:0:0\"})\n",
    "    snorkel_cursor.execute(\"INSERT INTO document (id, name) VALUES (currval('context_id_seq'), %(docid)s)\", {\"count\" : count, \"docid\": docid[0]})\n",
    "    snorkel_connection.commit()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 1055954/21460336 [39:06<13:07:06, 432.05it/s]"
     ]
    }
   ],
   "source": [
    "MAX_SENTENCES = 21460336\n",
    "#IMPORT THE SENTENCES DUMP\n",
    "cursor.execute(\"\"\"\n",
    "            SELECT docid, sentid, words, poses, ners, lemmas, dep_paths, dep_parents FROM final_merged_sentences ORDER BY docid, sentid LIMIT %(max_sentences)s;\n",
    "            \"\"\", {\"max_sentences\": MAX_SENTENCES})\n",
    "\n",
    "# Need to get document-level offsets for stable_id at the sentence level.\n",
    "count = 1\n",
    "\n",
    "doc_char_counts = {}\n",
    "\n",
    "\n",
    "#for sent in tqdm(cursor,total=20092495):\n",
    "for sent in tqdm(cursor,total=MAX_SENTENCES):\n",
    "    parsed_sent = {}\n",
    "    snorkel_cursor.execute(\"SELECT id FROM document WHERE name=%(docid)s\", {\"docid\" : sent[0]})\n",
    "    document_id = snorkel_cursor.fetchone()[0]\n",
    "    parsed_sent[\"document_id\"] = document_id\n",
    "    parsed_sent[\"position\"] = sent[1]\n",
    "    parsed_sent[\"words\"] = sent[2]\n",
    "    parsed_sent[\"pos_tags\"] = sent[3]\n",
    "    parsed_sent[\"ner_tags\"] = sent[4]\n",
    "    parsed_sent[\"lemmas\"] = sent[5]\n",
    "    parsed_sent[\"dep_labels\"] = sent[6]\n",
    "    parsed_sent[\"dep_parents\"] = sent[7]\n",
    "    parsed_sent[\"text\"] = \" \".join(word for word in parsed_sent[\"words\"])\n",
    "    parsed_sent[\"char_offsets\"] = [0 for i in range(len(parsed_sent[\"words\"]))]\n",
    "    parsed_sent[\"abs_char_offsets\"] = [0 for i in range (len(parsed_sent[\"words\"]))] \n",
    "    parsed_sent[\"entitiy_cids\"] = ['O']\n",
    "\n",
    "        \n",
    "    sentence_running_count = 0\n",
    "    for wordidx in range(len(parsed_sent[\"words\"])):\n",
    "        parsed_sent[\"char_offsets\"][wordidx] = sentence_running_count\n",
    "        sentence_running_count += len(parsed_sent[\"words\"][wordidx]) + 1\n",
    "\n",
    "    # This will probably be off by one...\n",
    "    if sent[0] in doc_char_counts:\n",
    "        sentence_start = doc_char_counts[sent[0]] + 1\n",
    "        doc_char_counts[sent[0]] += sentence_running_count\n",
    "    else:\n",
    "        sentence_start = 0\n",
    "        doc_char_counts[sent[0]] = sentence_running_count\n",
    "\n",
    "    # keep this running count as the sentence-level offset stable_id\n",
    "    try:\n",
    "        parsed_sent[\"stable_id\"] = sent[0] + \"::sentence:%s:%s\" % (sentence_start, doc_char_counts[sent[0]])\n",
    "        snorkel_cursor.execute(\n",
    "            \"\"\"INSERT INTO context (id, type, stable_id) VALUES (nextval('context_id_seq'), 'sentence', %(stable_id)s); \n",
    "                INSERT INTO sentence (id, document_id, position, words, pos_tags, ner_tags, lemmas, dep_labels, dep_parents, char_offsets, abs_char_offsets, text) VALUES \\\n",
    "                (currval('context_id_seq'), \\\n",
    "                    %(document_id)s, \\\n",
    "                    %(position)s, \\\n",
    "                    %(words)s, \\\n",
    "                    %(pos_tags)s, \\\n",
    "                    %(ner_tags)s,  \\\n",
    "                    %(lemmas)s, \\\n",
    "                    %(dep_labels)s, \\\n",
    "                    %(dep_parents)s, \\\n",
    "                    %(char_offsets)s, \\\n",
    "                    %(abs_char_offsets)s, \\\n",
    "                    %(text)s);\n",
    "                    \"\"\", parsed_sent)\n",
    "        snorkel_connection.commit()\n",
    "    except:\n",
    "        snorkel_connection.commit()\n",
    "        pass\n",
    "    count += 1\n",
    "\n",
    "snorkel_cursor.close()\n",
    "snorkel_connection.close()\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "time_elapsed = datetime.now() - start_time\n",
    "print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME NUMBERS TO CHECK WAS PROPERTY CONFIGURED\n",
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
